# Отчет по проделанной работе
-[x] I **Обучение модели**
-[x] II **Конвертация в ONNX**
-[ ] III **(Опционально) Конвертация в TensorRT (TRT)**
-[x] IV **Оптимизация модели средствами Torch/TensorFlow**
-[x] V **Оптимизация модели инструментами ONNX и (опционально) TRT**
-[x] VI **Разработка микросервиса предобработки данных**
-[x] VII **Развёртывание моделей с помощью Triton Inference Server**
-[X] VIII **Настройка мониторинга метрик**
-[ ] IX **Оркестрация сервисов с помощью docker-compose**
-[X] X **Тестирование и формирование отчёта**

## Обучение модели
    Обучена модель-классификатор на датасете cifar10. Обучение выполнено в ProjectHW.ipynb
## Конвертация в ONNX
    Модель конвертирована в onnx без сложностей. Конвертация выполнена в ProjectHW.ipynb
## III **(Опционально) Конвертация в TensorRT (TRT)
    Не проводилось
## Оптимизация модели средствами Torch
    Была произведено статическое квантование модели в ProjectHW.ipynb
## Оптимизация модели инструментами ONNX 
    Была произведено динамическое квантование модели в ProjectHW.ipynb
## Разработка микросервиса предобработки данных
    Был разработан микровервис на основе flask и torchvision для предобработки изображений. Изображение передается в контейнер виде строки
## Развертывание моделей с помощью Triton Inference Server
    Все четыре модели были загружены в Triton Inference Server
## Настройка мониторинга метрик
    Данные получаются из Triton Inference Server при помощи локального запуска Prometheus и Grafana
## Оркестрация сервисов с помощью docker-compose
    Не проводилось
## Тестирование и формирование отчёта
    Все выполненные задачи прошли тестирование, раннеры для контейнеров приложены.